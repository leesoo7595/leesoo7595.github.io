---
layout: post
title: "[ML] Generalization"
date: 2018-10-06
tags: [ML]
comments: true
---

# Generalization : peril-of-overfitting
## 일반화 : 과적합의 위험

적합한 모델을 찾게 되어도 그 후에 새 데이터를 추가할 때 이 모델은 주로 새 데이터에 적합하지 않은 것으로 확인이 된다. 이 모델은 학습한 데이터의 특성에 과적합한다.

과적합 모델은 학습하는 동안 손실이 적지만 새 데이터를 잘 예측하지 못한다.
현재 샘플(데이터)에 적합한 모델을 만들게 되면 이는 필요 이상으로 복잡한 모델이 될 가능성이 높아서 이는 과적합이 발생하게 된다.

**머신러닝의 근본적인 과제는 데이터 적합도를 유지하는 동시에 최대한 단순화하는 것이다.**

- 모델의 복잡성
- 학습 데이터에 대한 모델의 성능

이와 같은 요인을 기반으로 새 데이터에 맞게 모델이 일반화되는 정도를 통계적으로 설명하는 일반화 한계를 정의하게 된다.

즉, 머신러닝의 목표는 숨겨진 실제 확률 분포에서 추출되는 새 데이터를 잘 예측하는 것이다.
하지만 데이터 세트에서 모델을 만드는 경우 어떻게 이전에 보지 못한 데이터를 얻을 수 있을까?

- 학습 세트 : 모델을 학습시키기 위한 하위 세트
- 테스트 세트 : 모델을 테스트하기 위한 하위 세트

그에 대한 해결 방법으로 데이터 세트를 두 세트로 나누는 것이다.

- 테스트 세트가 충분히 크다.
- 같은 테스트 세트를 반복사용하지 않는다.

위와 같은 경우가 테스트 세트가 성능이 좋으며, 새 데이터에서도 성능이 좋다고 할 수 있다.

### 일반화에서는 기본적으로 3가지 사항을 가정한다.

1. 분포에서 독립적이고 동일하게(i.i.d.) 임의로 예를 추출한다. 즉, 예시가 서로 영향을 미치지 않는다.
2. 분포가 정상성을 보인다. 즉, 데이터 세트 내에서 분포가 달라지지 않는다.
3. 같은 분포를 따르는 부분에서 예를 추출한다.
